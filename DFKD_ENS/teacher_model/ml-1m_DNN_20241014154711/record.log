Namespace(dataset='ml-1m', model='DNN', emb_size=32, k=4, hd=[32, 32, 32, 32], epoch=60, batch_size=2048, lr=0.01, decay_gamma=0.3, weight_decay=1e-05, lr_decay_milestones='60', gpu=0, seed=None, workers=2)
-------------------------------
Use cuda:0
model: DNN(
  (embeddings): ModuleDict(
    (user_feature): Embedding(6041, 32)
    (item_feature): Embedding(3953, 32)
  )
  (linear_1): Linear(in_features=64, out_features=32, bias=True)
  (batchNorm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (activation_1): LeakyReLU(negative_slope=0.01)
  (linear_2): Linear(in_features=32, out_features=32, bias=True)
  (batchNorm_2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (activation_2): LeakyReLU(negative_slope=0.01)
  (linear_3): Linear(in_features=32, out_features=32, bias=True)
  (batchNorm_3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (activation_3): LeakyReLU(negative_slope=0.01)
  (linear_4): Linear(in_features=32, out_features=32, bias=True)
  (batchNorm_4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (activation_4): LeakyReLU(negative_slope=0.01)
  (fc): Linear(in_features=32, out_features=1, bias=True)
)
current_lr: 0.01
[1 / 60] train_loss: 0.5613058401988102
[1 / 60] val_loss: 0.5455792744954427
[1 / 60] auc: 0.7864699239709814 logloss:0.5455792693697382
--------------------------
current_lr: 0.01
[2 / 60] train_loss: 0.539001861291054
[2 / 60] val_loss: 0.5378422141075134
[2 / 60] auc: 0.7931706861214682 logloss:0.5378422069171855
--------------------------
current_lr: 0.01
[3 / 60] train_loss: 0.5310885921502725
[3 / 60] val_loss: 0.5331852026283741
[3 / 60] auc: 0.7983841053586295 logloss:0.5331852028162286
--------------------------
current_lr: 0.01
[4 / 60] train_loss: 0.5256813308367363
[4 / 60] val_loss: 0.5293777498106161
[4 / 60] auc: 0.8014176857776365 logloss:0.5293777439218313
--------------------------
current_lr: 0.01
[5 / 60] train_loss: 0.5216616580883662
[5 / 60] val_loss: 0.5280935453871886
[5 / 60] auc: 0.8031299482909589 logloss:0.5280935419409994
--------------------------
current_lr: 0.01
[6 / 60] train_loss: 0.5185100122140004
[6 / 60] val_loss: 0.5293548318247
[6 / 60] auc: 0.803664523713697 logloss:0.5293548279263881
--------------------------
current_lr: 0.01
[7 / 60] train_loss: 0.5160084435572991
[7 / 60] val_loss: 0.5264814384281635
[7 / 60] auc: 0.8045173286788334 logloss:0.5264814325184297
--------------------------
current_lr: 0.01
[8 / 60] train_loss: 0.513545855268454
[8 / 60] val_loss: 0.5236539524048567
[8 / 60] auc: 0.8065728961397535 logloss:0.5236539472540137
--------------------------
current_lr: 0.01
[9 / 60] train_loss: 0.5110588640738756
[9 / 60] val_loss: 0.5229993437727293
[9 / 60] auc: 0.806698213171093 logloss:0.5229993432600376
--------------------------
current_lr: 0.01
[10 / 60] train_loss: 0.5088874066487337
[10 / 60] val_loss: 0.52655095855395
[10 / 60] auc: 0.807326871307502 logloss:0.526550959056769
--------------------------
current_lr: 0.01
[11 / 60] train_loss: 0.5067120210482524
[11 / 60] val_loss: 0.52264836927255
[11 / 60] auc: 0.808088385888885 logloss:0.5226483627923809
--------------------------
current_lr: 0.01
[12 / 60] train_loss: 0.5050957242647807
[12 / 60] val_loss: 0.522955217709144
[12 / 60] auc: 0.807651511816931 logloss:0.5229552033506344
--------------------------
current_lr: 0.01
[13 / 60] train_loss: 0.5034814988191311
[13 / 60] val_loss: 0.5227282233536243
[13 / 60] auc: 0.8085029472778235 logloss:0.5227282188890441
--------------------------
current_lr: 0.01
[14 / 60] train_loss: 0.5019044342713478
[14 / 60] val_loss: 0.5209916060169538
[14 / 60] auc: 0.8092851326977712 logloss:0.5209916072183006
--------------------------
current_lr: 0.01
[15 / 60] train_loss: 0.5003923560564335
[15 / 60] val_loss: 0.5220751116673151
[15 / 60] auc: 0.809401281753719 logloss:0.5220751077422655
--------------------------
current_lr: 0.01
[16 / 60] train_loss: 0.4989389242270054
[16 / 60] val_loss: 0.521319384376208
[16 / 60] auc: 0.8097419597892581 logloss:0.5213193767418429
--------------------------
current_lr: 0.01
[17 / 60] train_loss: 0.4976974429228367
[17 / 60] val_loss: 0.5230395719408989
[17 / 60] auc: 0.809038715523646 logloss:0.5230395705002492
--------------------------
current_lr: 0.01
[18 / 60] train_loss: 0.4964181396441582
[18 / 60] val_loss: 0.5233501630524794
[18 / 60] auc: 0.8095390076838347 logloss:0.5233501610089116
--------------------------
current_lr: 0.01
[19 / 60] train_loss: 0.49517997816587106
[19 / 60] val_loss: 0.5194196520994107
[19 / 60] auc: 0.810737976045505 logloss:0.5194196464388284
--------------------------
current_lr: 0.01
[20 / 60] train_loss: 0.49406167444510335
[20 / 60] val_loss: 0.5218978729099035
[20 / 60] auc: 0.8106118075627686 logloss:0.5218978699478888
--------------------------
current_lr: 0.01
[21 / 60] train_loss: 0.49304083853195874
[21 / 60] val_loss: 0.5199650153517723
[21 / 60] auc: 0.8110452541261814 logloss:0.5199650191400852
--------------------------
current_lr: 0.01
[22 / 60] train_loss: 0.4919926663239797
[22 / 60] val_loss: 0.5220836754888296
[22 / 60] auc: 0.8100781101559531 logloss:0.5220836766461882
--------------------------
current_lr: 0.01
[23 / 60] train_loss: 0.4910647396857922
[23 / 60] val_loss: 0.5221124899884065
[23 / 60] auc: 0.8092604160742961 logloss:0.5221124795809741
--------------------------
current_lr: 0.01
[24 / 60] train_loss: 0.490406301846871
[24 / 60] val_loss: 0.5222456765671571
[24 / 60] auc: 0.8094636302892759 logloss:0.5222456654654672
--------------------------
current_lr: 0.01
[25 / 60] train_loss: 0.48946963502810553
[25 / 60] val_loss: 0.5212218910455704
[25 / 60] auc: 0.8100355169917521 logloss:0.5212218906112289
--------------------------
current_lr: 0.01
[26 / 60] train_loss: 0.4886563181877136
[26 / 60] val_loss: 0.5214171931147575
[26 / 60] auc: 0.8100309866076588 logloss:0.5214171924213366
--------------------------
current_lr: 0.01
[27 / 60] train_loss: 0.48791121672361326
[27 / 60] val_loss: 0.5218199578424295
[27 / 60] auc: 0.8106499496300388 logloss:0.5218199594745135
--------------------------
current_lr: 0.01
[28 / 60] train_loss: 0.4869675038716732
[28 / 60] val_loss: 0.5227414940794309
[28 / 60] auc: 0.8094375208060092 logloss:0.5227414971089127
--------------------------
current_lr: 0.01
[29 / 60] train_loss: 0.4866618342124499
[29 / 60] val_loss: 0.5216622029741605
[29 / 60] auc: 0.8103986418017805 logloss:0.5216622001926584
--------------------------
current_lr: 0.01
[30 / 60] train_loss: 0.48597831343993164
[30 / 60] val_loss: 0.520778842891256
[30 / 60] auc: 0.8104012875160234 logloss:0.5207788436521126
--------------------------
current_lr: 0.01
[31 / 60] train_loss: 0.48540417062930574
[31 / 60] val_loss: 0.5217705704271793
[31 / 60] auc: 0.8101135280510332 logloss:0.5217705648572749
--------------------------
current_lr: 0.01
[32 / 60] train_loss: 0.4850216583563731
[32 / 60] val_loss: 0.5222714692354202
[32 / 60] auc: 0.8101650217128669 logloss:0.522271466899313
--------------------------
current_lr: 0.01
[33 / 60] train_loss: 0.48454674726877456
[33 / 60] val_loss: 0.5217679583777984
[33 / 60] auc: 0.8107313827363838 logloss:0.521767954829598
--------------------------
current_lr: 0.01
[34 / 60] train_loss: 0.48404899109632543
[34 / 60] val_loss: 0.5211338847875595
[34 / 60] auc: 0.8100731499861101 logloss:0.5211338810489736
--------------------------
current_lr: 0.01
[35 / 60] train_loss: 0.4838517296772737
[35 / 60] val_loss: 0.5228222850710154
[35 / 60] auc: 0.8099826638213179 logloss:0.5228222787300659
--------------------------
current_lr: 0.01
[36 / 60] train_loss: 0.48340453390891736
[36 / 60] val_loss: 0.5237817416588465
[36 / 60] auc: 0.8096406801958387 logloss:0.5237817292908932
--------------------------
current_lr: 0.01
[37 / 60] train_loss: 0.48305729788083296
[37 / 60] val_loss: 0.5277455088992914
[37 / 60] auc: 0.8092010052846464 logloss:0.527745512851905
--------------------------
current_lr: 0.01
[38 / 60] train_loss: 0.48260276065422936
[38 / 60] val_loss: 0.5233279646684726
[38 / 60] auc: 0.809547555175882 logloss:0.5233279624756952
--------------------------
current_lr: 0.01
[39 / 60] train_loss: 0.4823642348631834
[39 / 60] val_loss: 0.5228238608688116
[39 / 60] auc: 0.8095515581978983 logloss:0.5228238563357489
--------------------------
current_lr: 0.01
[40 / 60] train_loss: 0.4822495066966766
[40 / 60] val_loss: 0.5233152508735657
[40 / 60] auc: 0.8104600930720195 logloss:0.523315250576192
--------------------------
current_lr: 0.01
[41 / 60] train_loss: 0.48180825037833974
[41 / 60] val_loss: 0.5240344398965439
[41 / 60] auc: 0.8091899059520767 logloss:0.524034430265924
--------------------------
current_lr: 0.01
[42 / 60] train_loss: 0.48154978920251895
[42 / 60] val_loss: 0.5242051569124063
[42 / 60] auc: 0.8094916497699337 logloss:0.5242051512379421
--------------------------
current_lr: 0.01
[43 / 60] train_loss: 0.4814558312678948
[43 / 60] val_loss: 0.5222525137166182
[43 / 60] auc: 0.8109892552942547 logloss:0.5222525168207343
--------------------------
current_lr: 0.01
[44 / 60] train_loss: 0.48138719407411723
[44 / 60] val_loss: 0.5209148849050204
[44 / 60] auc: 0.8102528518760876 logloss:0.520914879965746
--------------------------
current_lr: 0.01
[45 / 60] train_loss: 0.4813212064596323
[45 / 60] val_loss: 0.5239440153042475
[45 / 60] auc: 0.8093008226809424 logloss:0.523944016275833
--------------------------
current_lr: 0.01
[46 / 60] train_loss: 0.48101505117538645
[46 / 60] val_loss: 0.5233019975324472
[46 / 60] auc: 0.8092356513437898 logloss:0.5233019944452472
--------------------------
current_lr: 0.01
[47 / 60] train_loss: 0.48075858530325766
[47 / 60] val_loss: 0.5234094684322675
[47 / 60] auc: 0.8099159265879559 logloss:0.5234094693662346
--------------------------
current_lr: 0.01
[48 / 60] train_loss: 0.48057727706738007
[48 / 60] val_loss: 0.5232660695910454
[48 / 60] auc: 0.8091726099929141 logloss:0.5232660748447989
--------------------------
current_lr: 0.01
[49 / 60] train_loss: 0.48037004455541954
[49 / 60] val_loss: 0.523652384057641
[49 / 60] auc: 0.8096520801767032 logloss:0.5236523797011493
--------------------------
current_lr: 0.01
[50 / 60] train_loss: 0.48022157419950534
[50 / 60] val_loss: 0.5228258774926265
[50 / 60] auc: 0.8100534086033024 logloss:0.5228258699966171
--------------------------
current_lr: 0.01
[51 / 60] train_loss: 0.4802346584124443
[51 / 60] val_loss: 0.5229983801643053
[51 / 60] auc: 0.8094037930184794 logloss:0.522998374997692
--------------------------
current_lr: 0.01
[52 / 60] train_loss: 0.48013577598791857
[52 / 60] val_loss: 0.5253757356355587
[52 / 60] auc: 0.809353021800229 logloss:0.5253757306484831
--------------------------
current_lr: 0.01
[53 / 60] train_loss: 0.47989120819629766
[53 / 60] val_loss: 0.5241567213088274
[53 / 60] auc: 0.8095810358082722 logloss:0.5241567208597939
--------------------------
current_lr: 0.01
[54 / 60] train_loss: 0.47977701196303735
[54 / 60] val_loss: 0.524396413937211
[54 / 60] auc: 0.8090271264245261 logloss:0.5243964084734771
--------------------------
current_lr: 0.01
[55 / 60] train_loss: 0.4794442757582053
[55 / 60] val_loss: 0.5255625260372957
[55 / 60] auc: 0.8086090253497242 logloss:0.5255625221382078
--------------------------
current_lr: 0.01
[56 / 60] train_loss: 0.47975808733548875
[56 / 60] val_loss: 0.5236436352133751
[56 / 60] auc: 0.8087423820360684 logloss:0.5236436295676532
--------------------------
current_lr: 0.01
[57 / 60] train_loss: 0.47946589703743275
[57 / 60] val_loss: 0.5249580976863703
[57 / 60] auc: 0.8092427413577417 logloss:0.524958100001199
--------------------------
current_lr: 0.01
[58 / 60] train_loss: 0.47960432706735073
[58 / 60] val_loss: 0.5241960523029169
[58 / 60] auc: 0.8100226398069443 logloss:0.5241960528705667
--------------------------
current_lr: 0.01
[59 / 60] train_loss: 0.47926306151426756
[59 / 60] val_loss: 0.5239943961302439
[59 / 60] auc: 0.8094932011926308 logloss:0.5239943941992026
--------------------------
current_lr: 0.003
[60 / 60] train_loss: 0.47905784852993794
[60 / 60] val_loss: 0.5248264459272226
[60 / 60] auc: 0.809516666962023 logloss:0.5248264444047189
--------------------------
Test
val_auc: 0.8102645757929888, val_logloss: 0.5209166701008265
test_auc: 0.8105947408895455, test_logloss: 0.5197166134072093
