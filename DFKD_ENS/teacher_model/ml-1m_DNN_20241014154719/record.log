Namespace(dataset='ml-1m', model='DNN', emb_size=32, k=4, hd=[32, 32, 32, 32], epoch=60, batch_size=2048, lr=0.01, decay_gamma=0.3, weight_decay=1e-05, lr_decay_milestones='60', gpu=0, seed=42, workers=2)
-------------------------------
seed: 42
Use cuda:0
model: DNN(
  (embeddings): ModuleDict(
    (user_feature): Embedding(6041, 32)
    (item_feature): Embedding(3953, 32)
  )
  (linear_1): Linear(in_features=64, out_features=32, bias=True)
  (batchNorm_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (activation_1): LeakyReLU(negative_slope=0.01)
  (linear_2): Linear(in_features=32, out_features=32, bias=True)
  (batchNorm_2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (activation_2): LeakyReLU(negative_slope=0.01)
  (linear_3): Linear(in_features=32, out_features=32, bias=True)
  (batchNorm_3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (activation_3): LeakyReLU(negative_slope=0.01)
  (linear_4): Linear(in_features=32, out_features=32, bias=True)
  (batchNorm_4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (activation_4): LeakyReLU(negative_slope=0.01)
  (fc): Linear(in_features=32, out_features=1, bias=True)
)
current_lr: 0.01
[1 / 60] train_loss: 0.5617281808302953
[1 / 60] val_loss: 0.5491662559409937
[1 / 60] auc: 0.7864734326921461 logloss:0.5491662547821973
--------------------------
current_lr: 0.01
[2 / 60] train_loss: 0.5389849558854715
[2 / 60] val_loss: 0.5387718081474304
[2 / 60] auc: 0.7925956934526825 logloss:0.5387718047809019
--------------------------
current_lr: 0.01
[3 / 60] train_loss: 0.53223518041464
[3 / 60] val_loss: 0.5335441629091898
[3 / 60] auc: 0.7978400325020456 logloss:0.53354415339072
--------------------------
current_lr: 0.01
[4 / 60] train_loss: 0.5262223882552904
[4 / 60] val_loss: 0.5287319334844748
[4 / 60] auc: 0.8015405680401058 logloss:0.5287319291756915
--------------------------
current_lr: 0.01
[5 / 60] train_loss: 0.5222348313301037
[5 / 60] val_loss: 0.5270380812386671
[5 / 60] auc: 0.8034213082324627 logloss:0.5270380767325088
--------------------------
current_lr: 0.01
[6 / 60] train_loss: 0.5190351642859288
[6 / 60] val_loss: 0.5261026124159495
[6 / 60] auc: 0.8046590817438224 logloss:0.5261026028796708
--------------------------
current_lr: 0.01
[7 / 60] train_loss: 0.5162509863193219
[7 / 60] val_loss: 0.524986711020271
[7 / 60] auc: 0.805870700767221 logloss:0.5249867120222257
--------------------------
current_lr: 0.01
[8 / 60] train_loss: 0.5133480694049444
[8 / 60] val_loss: 0.5239618209501108
[8 / 60] auc: 0.8064980790395302 logloss:0.5239618194097281
--------------------------
current_lr: 0.01
[9 / 60] train_loss: 0.5109266248268959
[9 / 60] val_loss: 0.523369034131368
[9 / 60] auc: 0.8075617772932889 logloss:0.5233690251442997
--------------------------
current_lr: 0.01
[10 / 60] train_loss: 0.5085550901217338
[10 / 60] val_loss: 0.524384954944253
[10 / 60] auc: 0.8090765264325419 logloss:0.5243849534290269
--------------------------
current_lr: 0.01
[11 / 60] train_loss: 0.506094883573361
[11 / 60] val_loss: 0.521429060647885
[11 / 60] auc: 0.8089254649274293 logloss:0.5214290543241508
--------------------------
current_lr: 0.01
[12 / 60] train_loss: 0.5038683463365604
[12 / 60] val_loss: 0.5197874183456103
[12 / 60] auc: 0.8106858182551284 logloss:0.5197874108312877
--------------------------
current_lr: 0.01
[13 / 60] train_loss: 0.5015242626269658
[13 / 60] val_loss: 0.5203149989247322
[13 / 60] auc: 0.8103546291830104 logloss:0.5203149988557552
--------------------------
current_lr: 0.01
[14 / 60] train_loss: 0.49964877917216377
[14 / 60] val_loss: 0.5204714691887299
[14 / 60] auc: 0.809981332928959 logloss:0.5204714668359216
--------------------------
current_lr: 0.01
[15 / 60] train_loss: 0.497804322380286
[15 / 60] val_loss: 0.5191791324565808
[15 / 60] auc: 0.8112367755390973 logloss:0.519179128553037
--------------------------
current_lr: 0.01
[16 / 60] train_loss: 0.49609790635414613
[16 / 60] val_loss: 0.5219474515567223
[16 / 60] auc: 0.809945626304031 logloss:0.5219474503984775
--------------------------
current_lr: 0.01
[17 / 60] train_loss: 0.4948925255964964
[17 / 60] val_loss: 0.5211901441216469
[17 / 60] auc: 0.8101125842075967 logloss:0.521190133159333
--------------------------
current_lr: 0.01
[18 / 60] train_loss: 0.4937710814751112
[18 / 60] val_loss: 0.52075070515275
[18 / 60] auc: 0.8101981392661738 logloss:0.5207507040023559
--------------------------
current_lr: 0.01
[19 / 60] train_loss: 0.49273906029187714
[19 / 60] val_loss: 0.5235434745748838
[19 / 60] auc: 0.8100326114706801 logloss:0.5235434702618081
--------------------------
current_lr: 0.01
[20 / 60] train_loss: 0.4913722978188441
[20 / 60] val_loss: 0.5201437249779701
[20 / 60] auc: 0.810230162558297 logloss:0.520143723306349
--------------------------
current_lr: 0.01
[21 / 60] train_loss: 0.4905061106651257
[21 / 60] val_loss: 0.5221499726176262
[21 / 60] auc: 0.8093785339128639 logloss:0.5221499725307329
--------------------------
current_lr: 0.01
[22 / 60] train_loss: 0.48968043273840195
[22 / 60] val_loss: 0.5201620521644751
[22 / 60] auc: 0.8106302688175981 logloss:0.5201620511932209
--------------------------
current_lr: 0.01
[23 / 60] train_loss: 0.4890094193892601
[23 / 60] val_loss: 0.5240604194502035
[23 / 60] auc: 0.8088908578320073 logloss:0.5240604242135377
--------------------------
current_lr: 0.01
[24 / 60] train_loss: 0.48829456804654536
[24 / 60] val_loss: 0.5226649213582277
[24 / 60] auc: 0.8093577135643014 logloss:0.5226649198685002
--------------------------
current_lr: 0.01
[25 / 60] train_loss: 0.4875255240843846
[25 / 60] val_loss: 0.5238978763421377
[25 / 60] auc: 0.8089654637684478 logloss:0.5238978679580173
--------------------------
current_lr: 0.01
[26 / 60] train_loss: 0.4869155474962332
[26 / 60] val_loss: 0.520890132834514
[26 / 60] auc: 0.8102448985135112 logloss:0.5208901341294264
--------------------------
current_lr: 0.01
[27 / 60] train_loss: 0.4867160732929523
[27 / 60] val_loss: 0.5227534112830957
[27 / 60] auc: 0.8098575310300542 logloss:0.5227534088953629
--------------------------
current_lr: 0.01
[28 / 60] train_loss: 0.48605187481794604
[28 / 60] val_loss: 0.5226201278467973
[28 / 60] auc: 0.8092871610573713 logloss:0.5226201255829984
--------------------------
current_lr: 0.01
[29 / 60] train_loss: 0.48565846834427273
[29 / 60] val_loss: 0.5226733523110548
[29 / 60] auc: 0.8096240881540813 logloss:0.5226733445252223
--------------------------
current_lr: 0.01
[30 / 60] train_loss: 0.4851107800618196
[30 / 60] val_loss: 0.5221131934473912
[30 / 60] auc: 0.8093208477865304 logloss:0.5221131872234748
--------------------------
current_lr: 0.01
[31 / 60] train_loss: 0.48481961840238325
[31 / 60] val_loss: 0.5231712758541107
[31 / 60] auc: 0.8091697632980663 logloss:0.5231712748131043
--------------------------
current_lr: 0.01
[32 / 60] train_loss: 0.4844069018577918
[32 / 60] val_loss: 0.525229062885046
[32 / 60] auc: 0.8092807530566866 logloss:0.5252290649326294
--------------------------
current_lr: 0.01
[33 / 60] train_loss: 0.4842973886392055
[33 / 60] val_loss: 0.5252352723230919
[33 / 60] auc: 0.8085301719599001 logloss:0.525235263051179
--------------------------
current_lr: 0.01
[34 / 60] train_loss: 0.4836754139417257
[34 / 60] val_loss: 0.5235582453509172
[34 / 60] auc: 0.8091089034128662 logloss:0.5235582447706735
--------------------------
current_lr: 0.01
[35 / 60] train_loss: 0.4837514449388553
[35 / 60] val_loss: 0.5232713259756565
[35 / 60] auc: 0.8093476267005234 logloss:0.5232713301852415
--------------------------
current_lr: 0.01
[36 / 60] train_loss: 0.48332282457596215
[36 / 60] val_loss: 0.5214671467741331
[36 / 60] auc: 0.8097258408416671 logloss:0.5214671377371668
--------------------------
current_lr: 0.01
[37 / 60] train_loss: 0.48293848977639126
[37 / 60] val_loss: 0.5228660603364309
[37 / 60] auc: 0.8088636299120007 logloss:0.522866063002463
--------------------------
current_lr: 0.01
[38 / 60] train_loss: 0.4827783273580747
[38 / 60] val_loss: 0.5231299654891094
[38 / 60] auc: 0.8089680141645526 logloss:0.5231299660643263
--------------------------
current_lr: 0.01
[39 / 60] train_loss: 0.4828743828412814
[39 / 60] val_loss: 0.5236336526771387
[39 / 60] auc: 0.8089904719476286 logloss:0.5236336484633937
--------------------------
current_lr: 0.01
[40 / 60] train_loss: 0.4823831905157138
[40 / 60] val_loss: 0.5236910649885734
[40 / 60] auc: 0.808871187203555 logloss:0.5236910624072807
--------------------------
current_lr: 0.01
[41 / 60] train_loss: 0.48230036947971733
[41 / 60] val_loss: 0.5226472554107507
[41 / 60] auc: 0.8097859085992252 logloss:0.522647253976389
--------------------------
current_lr: 0.01
[42 / 60] train_loss: 0.48209054256096867
[42 / 60] val_loss: 0.5245851576328278
[42 / 60] auc: 0.8098418994857779 logloss:0.524585150745419
--------------------------
current_lr: 0.01
[43 / 60] train_loss: 0.4817729917856363
[43 / 60] val_loss: 0.5219744704663754
[43 / 60] auc: 0.809686369157679 logloss:0.521974472065128
--------------------------
current_lr: 0.01
[44 / 60] train_loss: 0.48151037792364754
[44 / 60] val_loss: 0.5222038229306539
[44 / 60] auc: 0.8093806771406016 logloss:0.5222038205963927
--------------------------
current_lr: 0.01
[45 / 60] train_loss: 0.4815443495145211
[45 / 60] val_loss: 0.5233143847435713
[45 / 60] auc: 0.8082024138918308 logloss:0.5233143796405466
--------------------------
current_lr: 0.01
[46 / 60] train_loss: 0.4810839614042869
[46 / 60] val_loss: 0.5234180589516958
[46 / 60] auc: 0.8088094450396353 logloss:0.5234180524418901
--------------------------
current_lr: 0.01
[47 / 60] train_loss: 0.48126638317719483
[47 / 60] val_loss: 0.523381169885397
[47 / 60] auc: 0.808736925296467 logloss:0.523381167486793
--------------------------
current_lr: 0.01
[48 / 60] train_loss: 0.4810949803927006
[48 / 60] val_loss: 0.522757555047671
[48 / 60] auc: 0.8087740393402438 logloss:0.5227575535509597
--------------------------
current_lr: 0.01
[49 / 60] train_loss: 0.4809703175838177
[49 / 60] val_loss: 0.524847491333882
[49 / 60] auc: 0.8086410866301357 logloss:0.52484748296331
--------------------------
current_lr: 0.01
[50 / 60] train_loss: 0.4808313326193736
[50 / 60] val_loss: 0.5237611482540766
[50 / 60] auc: 0.809079427506227 logloss:0.5237611455124455
--------------------------
current_lr: 0.01
[51 / 60] train_loss: 0.4805034849124077
[51 / 60] val_loss: 0.5228450174132983
[51 / 60] auc: 0.8091929544730146 logloss:0.5228450112893456
--------------------------
current_lr: 0.01
[52 / 60] train_loss: 0.4803342668673931
[52 / 60] val_loss: 0.5234743201484283
[52 / 60] auc: 0.8102246947529627 logloss:0.5234743183074496
--------------------------
current_lr: 0.01
[53 / 60] train_loss: 0.48068039417266845
[53 / 60] val_loss: 0.5239743255078793
[53 / 60] auc: 0.809532510194809 logloss:0.5239743209351925
--------------------------
current_lr: 0.01
[54 / 60] train_loss: 0.47994535733491944
[54 / 60] val_loss: 0.5234424819548925
[54 / 60] auc: 0.8091759482974944 logloss:0.5234424796784457
--------------------------
current_lr: 0.01
[55 / 60] train_loss: 0.480079850095969
[55 / 60] val_loss: 0.5243414336194595
[55 / 60] auc: 0.8090732864377457 logloss:0.5243414315288838
--------------------------
current_lr: 0.01
[56 / 60] train_loss: 0.4799392447257653
[56 / 60] val_loss: 0.5252239915231863
[56 / 60] auc: 0.8089727815477186 logloss:0.5252239818853491
--------------------------
current_lr: 0.01
[57 / 60] train_loss: 0.4797053262209281
[57 / 60] val_loss: 0.5244285600880781
[57 / 60] auc: 0.809269049822919 logloss:0.5244285552453773
--------------------------
current_lr: 0.01
[58 / 60] train_loss: 0.479913037786117
[58 / 60] val_loss: 0.524506077170372
[58 / 60] auc: 0.8092425893556336 logloss:0.5245060738788906
--------------------------
current_lr: 0.01
[59 / 60] train_loss: 0.47952459508027784
[59 / 60] val_loss: 0.5240619195004305
[59 / 60] auc: 0.809428811273741 logloss:0.5240619160604436
--------------------------
current_lr: 0.003
[60 / 60] train_loss: 0.479644541709851
[60 / 60] val_loss: 0.5247511838873228
[60 / 60] auc: 0.8089015886782207 logloss:0.5247511810544773
--------------------------
Test
val_auc: 0.8111555802170265, val_logloss: 0.5192625121903411
test_auc: 0.8114898380198775, test_logloss: 0.5181189559516483
